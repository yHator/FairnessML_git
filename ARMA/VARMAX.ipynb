{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd50ec2",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40089dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima_model import ARMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44753c98",
   "metadata": {},
   "source": [
    "# Data - CAISO Energy Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d540a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Demand 01/01/2020</th>\n",
       "      <th>00:00</th>\n",
       "      <th>00:05</th>\n",
       "      <th>00:10</th>\n",
       "      <th>00:15</th>\n",
       "      <th>00:20</th>\n",
       "      <th>00:25</th>\n",
       "      <th>00:30</th>\n",
       "      <th>00:35</th>\n",
       "      <th>00:40</th>\n",
       "      <th>...</th>\n",
       "      <th>23:15</th>\n",
       "      <th>23:20</th>\n",
       "      <th>23:25</th>\n",
       "      <th>23:30</th>\n",
       "      <th>23:35</th>\n",
       "      <th>23:40</th>\n",
       "      <th>23:45</th>\n",
       "      <th>23:50</th>\n",
       "      <th>23:55</th>\n",
       "      <th>00:00.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demand</td>\n",
       "      <td>21533</td>\n",
       "      <td>21429</td>\n",
       "      <td>21320</td>\n",
       "      <td>21272</td>\n",
       "      <td>21193</td>\n",
       "      <td>21109</td>\n",
       "      <td>21006</td>\n",
       "      <td>20961</td>\n",
       "      <td>20916</td>\n",
       "      <td>...</td>\n",
       "      <td>20920</td>\n",
       "      <td>20809</td>\n",
       "      <td>20681</td>\n",
       "      <td>20574</td>\n",
       "      <td>20494</td>\n",
       "      <td>20383</td>\n",
       "      <td>20297</td>\n",
       "      <td>20242</td>\n",
       "      <td>20128</td>\n",
       "      <td>20025.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Net Demand 01/01/2020  00:00  00:05  00:10  00:15  00:20  00:25  00:30  \\\n",
       "1                Demand  21533  21429  21320  21272  21193  21109  21006   \n",
       "\n",
       "   00:35  00:40  ...  23:15  23:20  23:25  23:30  23:35  23:40  23:45  23:50  \\\n",
       "1  20961  20916  ...  20920  20809  20681  20574  20494  20383  20297  20242   \n",
       "\n",
       "   23:55  00:00.1  \n",
       "1  20128  20025.0  \n",
       "\n",
       "[1 rows x 290 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caiso_df = pd.read_csv(\"/Users/yukahatori/A_Fairness/CAISO-netdemand-20200101.csv\", on_bad_lines = 'skip')\n",
    "caiso_df.drop(labels = [0,2,3], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df5d84e",
   "metadata": {},
   "source": [
    "# Data - Climate Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79c81331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------NEW COLUMNS-----------------------------\n",
      "      HLY_TEMP_NORMAL\n",
      "0                48.8\n",
      "1                48.5\n",
      "2                47.6\n",
      "3                47.2\n",
      "4                46.8\n",
      "...               ...\n",
      "8755             51.5\n",
      "8756             51.0\n",
      "8757             50.5\n",
      "8758             49.8\n",
      "8759             49.4\n",
      "\n",
      "[8727 rows x 1 columns]\n",
      "---------------------------------DESCRIBE------------------------------\n",
      "       HLY_TEMP_NORMAL\n",
      "count      8727.000000\n",
      "mean         57.432314\n",
      "std           5.892017\n",
      "min          46.400000\n",
      "25%          52.900000\n",
      "50%          57.000000\n",
      "75%          61.100000\n",
      "max          72.300000\n"
     ]
    }
   ],
   "source": [
    "#January 1st, 24 hours \n",
    "df = pd.read_csv(\"/Users/yukahatori/A_Fairness/USW00023234.csv\")\n",
    "\n",
    "#drop columns we don't need\n",
    "df.drop('STATION', axis=1, inplace=True)\n",
    "df.drop('NAME', axis=1, inplace=True)\n",
    "df.drop('LATITUDE', axis=1, inplace=True)\n",
    "df.drop('LONGITUDE', axis=1, inplace=True)\n",
    "df.drop('ELEVATION', axis=1, inplace=True)\n",
    "df.drop('month', axis=1, inplace=True)\n",
    "df.drop('hour', axis=1, inplace=True)\n",
    "df.drop('day', axis=1, inplace=True)\n",
    "\n",
    "#checks the flags and removes any rows corresponding with 'M' which means the data is missing\n",
    "measurementFlags = list(df.filter(regex='meas'))\n",
    "for flag in measurementFlags:\n",
    "    df = df[~df[flag].str.contains('M')]\n",
    "\n",
    "completenessFlags = list(df.filter(regex='meas'))\n",
    "for flag in completenessFlags:\n",
    "    df = df[~df[flag].str.contains('-9999')]\n",
    "        \n",
    "#get rid of all measurement and completeness flags\n",
    "df = df[df.columns.drop(list(df.filter(regex='meas')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='comp')))]\n",
    "\n",
    "#rename columns\n",
    "df.columns = ['date', 'HLY_TEMP_NORMAL', 'years_HLY_TEMP_NORMAL', 'HLY_TEMP_10PCTL',\n",
    "       'years_HLY_TEMP_10PCTL', 'HLY_TEMP_90PCTL', 'years_HLY_TEMP_90PCTL',\n",
    "       'HLY_DEWP_NORMAL', 'years_HLY_DEWP_NORMAL', 'HLY_DEWP_10PCTL',\n",
    "       'years_HLY_DEWPv10PCTL', 'HLY_DEWP_90PCTL', 'years_HLY_DEWP_90PCTL',\n",
    "       'HLY_PRES_NORMAL', 'years_HLY_PRES_NORMAL', 'HLY_PRES_10PCTL',\n",
    "       'years_HLY_PRES_10PCTL', 'HLY_PRES_90PCTL', 'years_HLY_PRES_90PCTL',\n",
    "       'HLY_CLDH_NORMAL', 'years_HLY_CLDH_NORMAL', 'HLY_HTDH_NORMAL',\n",
    "       'years_HLY_HTDH_NORMAL', 'HLY_CLOD_PCTCLR', 'years_HLY_CLOD_PCTCLR',\n",
    "       'HLY_CLOD_PCTFEW', 'years_HLY_CLOD_PCTFEW', 'HLY_CLOD_PCTSCT',\n",
    "       'years_HLY_CLOD_PCTSCT', 'HLY_CLOD_PCTBKN', 'years_HLY_CLOD_PCTBKN',\n",
    "       'HLY_CLOD_PCTOVC', 'years_HLY_CLOD_PCTOVC', 'HLY_HIDX_NORMAL',\n",
    "       'years_HLY_HIDX_NORMAL', 'HLY_WCHL_NORMAL', 'years_HLY_WCHL_NORMAL',\n",
    "       'HLY_WIND_AVGSPD', 'years_HLY_WIND_AVGSPD', 'HLY_WIND_PCTCLM',\n",
    "       'years_HLY_WIND_PCTCLM', 'HLY_WIND_VCTDIR', 'years_HLY_WIND_VCTDIR',\n",
    "       'HLY_WIND_VCTSPD', 'years_HLY_WIND_VCTSPD', 'HLY_WIND_1STDIR',\n",
    "       'years_HLY-WIND-1STDIR', 'HLY_WIND_1STPCT', 'years_HLY_WIND_1STPCT',\n",
    "       'HLY_WIND_2NDDIR', 'years_HLY_WIND_2NDDIR', 'HLY_WIND_2NDPCT',\n",
    "       'years_HLY_WIND_2NDPCT']\n",
    "#DROPPING COLUMNS FOR TESTING\n",
    "df = df.drop(columns=['date','years_HLY_TEMP_NORMAL', 'HLY_TEMP_10PCTL',\n",
    "       'years_HLY_TEMP_10PCTL', 'HLY_TEMP_90PCTL', 'years_HLY_TEMP_90PCTL',\n",
    "       'HLY_DEWP_NORMAL', 'years_HLY_DEWP_NORMAL', 'HLY_DEWP_10PCTL',\n",
    "       'years_HLY_DEWPv10PCTL', 'HLY_DEWP_90PCTL', 'years_HLY_DEWP_90PCTL',\n",
    "       'HLY_PRES_NORMAL', 'years_HLY_PRES_NORMAL', 'HLY_PRES_10PCTL',\n",
    "       'years_HLY_PRES_10PCTL', 'HLY_PRES_90PCTL', 'years_HLY_PRES_90PCTL',\n",
    "       'HLY_CLDH_NORMAL', 'years_HLY_CLDH_NORMAL', 'HLY_HTDH_NORMAL',\n",
    "       'years_HLY_HTDH_NORMAL', 'HLY_CLOD_PCTCLR', 'years_HLY_CLOD_PCTCLR',\n",
    "       'HLY_CLOD_PCTFEW', 'years_HLY_CLOD_PCTFEW', 'HLY_CLOD_PCTSCT',\n",
    "       'years_HLY_CLOD_PCTSCT', 'HLY_CLOD_PCTBKN', 'years_HLY_CLOD_PCTBKN',\n",
    "       'HLY_CLOD_PCTOVC', 'years_HLY_CLOD_PCTOVC', 'HLY_HIDX_NORMAL',\n",
    "       'years_HLY_HIDX_NORMAL', 'HLY_WCHL_NORMAL', 'years_HLY_WCHL_NORMAL',\n",
    "       'HLY_WIND_AVGSPD', 'years_HLY_WIND_AVGSPD', 'HLY_WIND_PCTCLM',\n",
    "       'years_HLY_WIND_PCTCLM', 'HLY_WIND_VCTDIR', 'years_HLY_WIND_VCTDIR',\n",
    "       'HLY_WIND_VCTSPD', 'years_HLY_WIND_VCTSPD', 'HLY_WIND_1STDIR',\n",
    "       'years_HLY-WIND-1STDIR', 'HLY_WIND_1STPCT', 'years_HLY_WIND_1STPCT',\n",
    "       'HLY_WIND_2NDDIR', 'years_HLY_WIND_2NDDIR', 'HLY_WIND_2NDPCT',\n",
    "       'years_HLY_WIND_2NDPCT'])\n",
    "print(\"-------------------------------NEW COLUMNS-----------------------------\")\n",
    "print(df)\n",
    "print('---------------------------------DESCRIBE------------------------------')\n",
    "#describe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fed41b",
   "metadata": {},
   "source": [
    "# Test if data is stationary or not\n",
    "\n",
    "https://campus.datacamp.com/courses/arima-models-in-python/chapter-1-arma-models?ex=6\n",
    "\n",
    "Notes on ARMA: https://docs.google.com/document/d/1CO71cEz1Jd45uqUN8-WcvmGDbol9hAA5HHZV0rl7z60/edit\n",
    "\n",
    "Transforms to make data stationary: https://campus.datacamp.com/courses/arima-models-in-python/chapter-1-arma-models?ex=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d08403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic: -0.04676318489294472\n",
      "p-value: 0.9544896699145867\n",
      "critical values:  37\n"
     ]
    }
   ],
   "source": [
    "# Import augmented dicky-fuller test function\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Run test\n",
    "\n",
    "result = adfuller(df['HLY_TEMP_NORMAL'])\n",
    "\n",
    "# Print test statistic\n",
    "#The more negative this value is, the more likely it is stationary?\n",
    "print(\"Test statistic:\", result[0])\n",
    "\n",
    "# Print p-value\n",
    "#If it is less than 0.05, reject non-stationary\n",
    "print(\"p-value:\",result[1])\n",
    "\n",
    "print(\"critical values: \",result[2]) \n",
    "\n",
    "#Input: the columns of the dataframe(columns), the dataframe (df)\n",
    "def check_stationary(columns, df):\n",
    "    for column in columns: \n",
    "        result = adfuller(df[column])\n",
    "        \n",
    "        if result[1] < 0.05:\n",
    "            print(\"Reject non-stationary for \", column)\n",
    "    print(\"Dataframe is stationary\")\n",
    "\n",
    "#continues to take the difference for that column until it is stationary\n",
    "#differencing isn't always the best method, check out log and other stuff\n",
    "def make_stationary(column, df):\n",
    "    done = False\n",
    "    \n",
    "    while (not done):\n",
    "        df_stationary = diff().dropna()\n",
    "        result = adfuller(df[column])\n",
    "        \n",
    "        pVal = result[1]\n",
    "        if (pVal < 0.05):\n",
    "            done = True\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41f98ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe is stationary\n"
     ]
    }
   ],
   "source": [
    "col_var = df.columns\n",
    "#the columns have time as a column, which we don't want\n",
    "col_var = col_var[1:]\n",
    "check_stationary(col_var, df)\n",
    "# check_Stationary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd7701",
   "metadata": {},
   "source": [
    "# Determine p and q for model\n",
    "\n",
    "With python code: https://www.quantstart.com/articles/Autoregressive-Moving-Average-ARMA-p-q-Models-for-Time-Series-Analysis-Part-3/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e087cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a326e6bb",
   "metadata": {},
   "source": [
    "# ARMAX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59bcbd8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yv/7r0htvks26q7nhdm7l86zm7m0000gn/T/ipykernel_1279/2433601627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marima_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mARMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaiso_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HLY_TEMP_NORMAL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, order, exog, dates, freq, missing)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARIMA_DEPRECATION_WARN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;31m# GH 2575\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0marray_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'endog'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, dates, freq, missing, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m     def __init__(self, endog, exog=None, dates=None, freq=None,\n\u001b[1;32m    410\u001b[0m                  missing='none', **kwargs):\n\u001b[0;32m--> 411\u001b[0;31m         super(TimeSeriesModel, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[1;32m    412\u001b[0m                                               **kwargs)\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'missing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[1;32m     78\u001b[0m                                       **kwargs)\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[1;32m    673\u001b[0m                  **kwargs)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_endog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_exog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m_convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n\u001b[0m\u001b[1;32m    509\u001b[0m                              \"Check input data with np.asarray(data).\")\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPandasData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_endog_exog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "model = ARMA(caiso_df, order=(1, 1), exog = df['HLY_TEMP_NORMAL']).fit() # fit model\n",
    "print(np.asarray(df))\n",
    "# print(model.summary())\n",
    "# plt.plot(x)\n",
    "# plt.plot(model.predict(), color='red')\n",
    "# plt.title('RSS: %.4f'% sum((model.fittedvalues-x)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b4617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0adac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
